---
#authorï¼›zhang
- name: "Install dependency"
  package:
    name:
      - libnetfilter_cthelper
      - libnetfilter_cttimeout
      - libnetfilter_queue
      - conntrack-tools
      - ipvsadm
      - ipset
      - socat
    state: present
  when:
    - ansible_os_family in ['RedHat', 'AlmaLinux', 'Rocky']
  tags: worker_app

- name: "Install dependency"
  package:
    name:
      - libnetfilter-cthelper0
      - libnetfilter-cttimeout1
      - libnetfilter-queue1
      - libnetfilter-conntrack3
      - conntrack
      - ipvsadm
      - ipset
      - socat
    state: present
  when:
    - ansible_os_family in ["Debian"]
  tags: worker_app

- name: "Enabled modlue"
  modprobe:
    name: "{{ item.line }}"
    state: present
  with_items:
    - {line: 'ip_vs' }
    - {line: 'ip_vs_rr' }
    - {line: 'ip_vs_wrr' }
    - {line: 'ip_vs_lc' }
    - {line: 'ip_vs_wlc' }
    - {line: 'ip_vs_sh' }
    - {line: 'ip_vs_dh' }
    - {line: 'ip_vs_sed' }
    - {line: 'ip_vs_nq' }
    - {line: 'bridge' }
    - {line: 'overlay' }
    - {line: 'ip_tables' }
    - {line: 'iptable_filter' }
    - {line: 'br_netfilter' }
  tags: worker_mod

- name: "Enabled conntrack modlue < 4.19.0"
  modprobe:
    name: "nf_conntrack_ipv4"
    state: present
  when: ((ansible_os_family in ['RedHat', 'AlmaLinux', 'Rocky'] and ansible_distribution_major_version != '8') or ansible_os_family in ['Debian']) and
        ansible_kernel.split('-')[0] is version('4.19.0', '<')
  tags: worker_mod

- name: "Enabled conntrack modlue > 4.19.0"
  modprobe:
    name: "nf_conntrack"
    state: present
  when: (ansible_os_family in ['RedHat', 'AlmaLinux', 'Rocky'] and ansible_distribution_major_version == '8') or
        ansible_kernel.split('-')[0] is version('4.19.0', '>=')
  tags: worker_mod

- name: "Modify sysctl"
  sysctl:
    name: "{{ item.name }}"
    value: "{{ item.value }}"
    state: present
    reload: yes
  with_items:
    - {name: 'net.netfilter.nf_conntrack_max',value: '2310720' }
    - {name: 'net.bridge.bridge-nf-call-iptables',value: '1' }
    - {name: 'net.bridge.bridge-nf-call-ip6tables',value: '1' }
  tags: worker_sysctl

- name: "Create kubernetes directory"
  file:
    path: "{{ item.line }}"
    owner: root
    group: root
    mode: 0755
    state: directory
  with_items:
    - {line: '/etc/kubernetes/pki'}
    - {line: '/etc/kubernetes/manifests'}
    - {line: "{{ kubernetes.kubelet_dir }}"}
  tags: dir

- name: "Create kubelet directory"
  file:
    path: "/etc/sysconfig"
    owner: root
    group: root
    mode: 0755
    state: directory
  when:
    - ansible_os_family in ["Debian"]
  tags: dir

- name: "Install worker node"
  get_url:
    url: "{{ item.line }}"
    dest: /usr/bin/
    owner: root
    group: root
    mode: 0750
  with_items:
    - { line: "{{ kubernetes.download_url }}/kubelet"}
    - { line: "{{ kubernetes.download_url }}/kube-proxy"}
  tags: install_worker

- name: "Distribution worker certs"
  copy:
    src: "{{ item.line }}"
    dest: "/etc/kubernetes/pki/"
    owner: root
    group: root
    mode: 0644
  with_items:
    - {line: "{{ cert.dir }}/ca.pem"}
    - {line: "{{ cert.dir }}/ca.key"}
    - {line: "{{ cert.dir }}/{{ ansible_default_ipv4.address }}/kube-proxy.pem"}
    - {line: "{{ cert.dir }}/{{ ansible_default_ipv4.address }}/kube-proxy.key"}
  tags:
    - dis_worker_certs
    - dis_certs

- name: "Get bootstrap-token-id"
  shell: "cat {{ cert.dir }}/token | grep -v '^#' | awk -F '.' '{print $1}'"
  register: token_id
  connection: local
  tags:
    - get_token_id
    - bootstrap_token

- name: "Get bootstrap-token-secret"
  shell: "cat {{ cert.dir }}/token | grep -v '^#' | awk -F '.' '{print $2}'"
  register: token_secret
  connection: local
  tags:
    - get_token_secret
    - bootstrap_token

- name: "Distribution worker kubeconfig"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0640
    dest: "{{ item.dest }}"
  with_items:
    - {src: "bootstrap.kubeconfig.j2",dest: "/etc/kubernetes/bootstrap.kubeconfig" }
    - {src: "proxy.kubeconfig.j2",dest: "/etc/kubernetes/proxy.kubeconfig" }
  tags: dis_worker_kubeconfig

- name: "Distribution worker config"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0640
    dest: "{{ item.dest }}"
  with_items:
    - {src: "kubelet.conf.j2",dest: "/etc/kubernetes/kubelet.conf" }
    - {src: "10-kubelet.conf.j2",dest: "/etc/sysconfig/kubelet" }
    - {src: "kube-proxy.conf.j2",dest: "/etc/kubernetes/kube-proxy.conf" }
  tags: dis_worker_config

- name: "Distribution worker system unit"
  template:
    src: "{{ item.src }}"
    owner: root
    group: root
    mode: 0644
    dest: "{{ item.dest }}"
  with_items:
    - {src: "kubelet.service.j2",dest: "/usr/lib/systemd/system/kubelet.service" }
    - {src: "kube-proxy.service.j2",dest: "/usr/lib/systemd/system/kube-proxy.service" }
  tags: dis_worker_systemd

- name: "Check if bootstrap-token exists"
  shell: kubectl -n kube-system get secret bootstrap-token-{{ token_id.stdout }}
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: bootstrap_token_ready
  tags: bootstrap

- name: "Create bootstrap-token secret"
  when: bootstrap_token_ready.rc != 0
  shell: kubectl -n kube-system create secret generic bootstrap-token-{{ token_id.stdout }} --type 'bootstrap.kubernetes.io/token' --from-literal description="cluster bootstrap token" --from-literal token-id={{ token_id.stdout }} --from-literal token-secret={{ token_secret.stdout }} --from-literal usage-bootstrap-authentication=true --from-literal usage-bootstrap-signing=true
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  tags: bootstrap

- name: "Check if clusterrolebinding kubelet-bootstrap exists"
  shell: kubectl get clusterrolebinding kubelet-bootstrap
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: kubelet_bootstrap_ready
  tags: bootstrap

- name: "Create clusterrolebinding kubelet-bootstrap"
  when: kubelet_bootstrap_ready.rc != 0
  shell: kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  tags: bootstrap

- name: "Check if node-autoapprove-bootstrap exists"
  shell: kubectl get clusterrolebinding node-autoapprove-bootstrap
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: node_autoapprove_bootstrap_ready
  tags: bootstrap

- name: "Create clusterrolebinding node-autoapprove-bootstrap"
  when: node_autoapprove_bootstrap_ready.rc != 0
  shell: kubectl create clusterrolebinding node-autoapprove-bootstrap --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  tags: bootstrap

- name: "Check if clusterrolebinding node-autoapprove-certificate-rotation exists"
  shell: kubectl get clusterrolebinding node-autoapprove-certificate-rotation
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: node_autoapprove_certificate_rotation_ready
  tags: bootstrap

- name: "Create clusterrolebinding node-autoapprove-certificate-rotation"
  when: node_autoapprove_certificate_rotation_ready.rc != 0
  shell: kubectl create clusterrolebinding node-autoapprove-certificate-rotation --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  tags: bootstrap

- name: "Restart kubelet"
  systemd:
    name: kubelet
    state: restarted
    daemon_reload: yes
    enabled: yes
    masked: false
  tags: restart_kubelet

- name: "Waiting kubelet starting"
  wait_for:
    host: "{{ ansible_default_ipv4.address }}"
    port: 10250
    delay: 5
    sleep: 2
  tags: healthcheck

- name: "kubelet health check"
  uri:
    url: "http://{{ ansible_default_ipv4.address }}:10248/healthz"
    return_content: yes
    validate_certs: no
  register: kubelet
  failed_when: "'ok' not in kubelet.content"
  connection: local
  tags: healthcheck

- name: "Restart kube-proxy"
  systemd:
    name: kube-proxy
    state: restarted
    daemon_reload: yes
    enabled: yes
    masked: false
  tags: restart_proxy

- name: "Waiting kube-proxy starting"
  wait_for:
    host: "{{ ansible_default_ipv4.address }}"
    port: 10256
    delay: 5
    sleep: 2
  tags: healthcheck

- name: "kube-proxy health check"
  uri:
    url: "http://{{ ansible_default_ipv4.address }}:10256/healthz"
    return_content: yes
    validate_certs: no
    status_code: 200
  register: proxy
  connection: local
  tags: healthcheck

- name: "Check whether the worker is ready?"
  shell: "kubectl get node | grep {{ ansible_hostname.split('-')[-2:] | join('-') | lower  }}-{{ ansible_default_ipv4.address }}"
  register: worker_status
  until: '"Ready" in worker_status.stdout'
  retries: 5
  delay: 3
  delegate_to: "{{ groups['master'][0] }}"
  with_items:
    - "{{ groups['master'] }}"
  tags:
    - create_label

- name: "Create taint for control-plane"
  shell: "kubectl taint nodes {{ hostvars[item].hostname.split('-')[-2:] | join('-') | lower }}-{{ item }} node-role.kubernetes.io/control-plane=:NoSchedule --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['master'] }}"
  tags:
    - create_master_label
    - create_master_taint
    - create_label

- name: "Create label for master"
  shell: "kubectl label nodes {{ hostvars[item].hostname.split('-')[-2:] | join('-') | lower }}-{{ item }} node-role.kubernetes.io/control-plane= --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['master'] }}"
  tags:
    - create_master_label
    - create_label

- name: "Create label for worker"
  shell: "kubectl label nodes {{ hostvars[item].hostname.split('-')[-2:] | join('-') | lower }}-{{ item }} node-role.kubernetes.io/worker= --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  with_items:
    - "{{ groups['worker'] }}"
  tags:
    - create_worker_label
    - create_label

- name: "Create taint for gpu worker"
  when: gpu is defined and gpu == 'true'
  shell: "kubectl taint nodes {{ ansible_hostname.split('-')[-2:] | join('-') | lower }}-{{ ansible_default_ipv4.address }} nvidia.com/gpu=:NoSchedule --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: false
  tags:
    - create_gpu_taint
    - create_gpu

- name: "Create label for gpu worker"
  when: gpu is defined and gpu == 'true'
  shell: "kubectl label nodes {{ ansible_hostname.split('-')[-2:] | join('-') | lower }}-{{ ansible_default_ipv4.address }} nvidia.com/gpu=true --overwrite"
  delegate_to: "{{ groups['master'][0] }}"
  run_once: false
  tags:
    - create_gpu_label
    - create_gpu
